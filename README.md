# ğŸ¤– CHIPPY - AI Tutoring Robot

<div align="center">

![CHIPPY Logo](https://img.shields.io/badge/CHIPPY-AI%20Tutor-blue?style=for-the-badge&logo=robot)
[![Python](https://img.shields.io/badge/Python-3.9+-blue?style=flat-square&logo=python)](https://python.org)
[![Azure](https://img.shields.io/badge/Azure-Cognitive%20Services-blue?style=flat-square&logo=microsoft-azure)](https://azure.microsoft.com)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)

**An intelligent voice-enabled AI tutoring robot that provides personalized math education for students K-8**

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“Š Data Flow](#-data-flow) â€¢ [ğŸ› ï¸ Setup](#ï¸-setup) â€¢ [ğŸ’¬ Usage](#-usage) â€¢ [ğŸ—ï¸ Architecture](#ï¸-architecture)

</div>

---

## ğŸŒŸ What is CHIPPY?

CHIPPY is an advanced AI-powered tutoring robot designed to revolutionize math education through natural voice interactions. Using cutting-edge Azure Cognitive Services and intelligent conversation flows, CHIPPY provides:

- ğŸ¤ **Voice-First Learning**: Natural speech recognition and synthesis
- ğŸ§  **Intelligent Tutoring**: AI-powered responses tailored to student needs
- ğŸ“š **Curriculum Aligned**: Covers K-8 math standards (California Common Core)
- ğŸ”’ **Privacy-First**: Built-in anonymization for student data protection
- ğŸ“± **Interactive**: Real-time voice conversations with immediate feedback

---

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/apex-tutoring-robot/Ai-Agent.git
cd Ai-Agent

# Set up virtual environment
python3 -m venv azure-venv
source azure-venv/bin/activate  # On Windows: azure-venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp azure-speech-to-text/.env.example azure-speech-to-text/.env
# Edit .env with your Azure credentials

# Run CHIPPY
cd azure-speech-to-text/src
python copy_voice_interaction_demo.py
```

---

## ğŸ“Š Data Flow

```mermaid
graph TD
    A[ğŸ¤ Student Voice Input] --> B[ğŸ”Š Azure Speech-to-Text]
    B --> C[ğŸ›¡ï¸ Privacy Manager]
    C --> D[ğŸ“ Anonymized Text]
    D --> E[ğŸ§  Azure AI Flow]
    E --> F[ğŸ¯ Personalized Response]
    F --> G[ğŸ”Š Azure Text-to-Speech]
    G --> H[ğŸµ Audio Response]
    H --> I[ğŸ‘‚ Student Hears Response]
    
    J[ğŸ“š Textbook Content] --> K[âš™ï¸ Preprocessing]
    K --> L[ğŸ“Š Structured Knowledge Base]
    L --> E
    
    style A fill:#e1f5fe
    style E fill:#f3e5f5
    style H fill:#e8f5e8
    style L fill:#fff3e0
```

### Data Processing Pipeline

1. **ğŸ¤ Audio Capture**: Student speaks into microphone
2. **ğŸ”Š Speech Recognition**: Azure Speech-to-Text converts audio to text
3. **ğŸ›¡ï¸ Privacy Protection**: PrivacyManager anonymizes personal information
4. **ğŸ§  AI Processing**: Azure Flow processes the anonymized query
5. **ğŸ“š Knowledge Retrieval**: System accesses relevant curriculum content
6. **ğŸ¯ Response Generation**: AI generates personalized tutoring response
7. **ğŸ”Š Speech Synthesis**: Azure Text-to-Speech converts response to audio
8. **ğŸ‘‚ Audio Playback**: Student hears the tutoring response

---

## ğŸ› ï¸ Setup

### Prerequisites
- ğŸ Python 3.9+
- ğŸ¤ Microphone and speakers/headphones
- â˜ï¸ Azure Cognitive Services account
- ğŸ”‘ Azure Speech Services API key

### 1. Azure Services Setup

1. **Create Azure Cognitive Services Resource**:
   - Go to [Azure Portal](https://portal.azure.com)
   - Create a new "Speech" resource
   - Note your `API Key` and `Region`

2. **Azure AI Flow Setup** (Optional for advanced features):
   - Set up Azure Machine Learning workspace
   - Deploy your flow endpoint
   - Get the endpoint URL and API key

### 2. Environment Configuration

Create your environment file:
```bash
cp azure-speech-to-text/.env.example azure-speech-to-text/.env
```

Edit `.env` with your credentials:
```env
# Azure Speech Services
AZURE_SPEECH_KEY=your_speech_api_key_here
AZURE_SPEECH_REGION=your_region_here

# Azure Flow (Optional)
FLOW_ENDPOINT=your_flow_endpoint_url
FLOW_API_KEY=your_flow_api_key

# Session Configuration
SESSION_ID_PREFIX=CHIPPY_
```

### 3. Install Dependencies

```bash
# Create and activate virtual environment
python3 -m venv azure-venv
source azure-venv/bin/activate

# Install required packages
pip install -r requirements.txt

# For Linux users - install PyAudio dependencies
sudo apt-get install python3-pyaudio portaudio19-dev
```

---

## ğŸ’¬ Usage

### Basic Voice Interaction

```bash
cd azure-speech-to-text/src
python copy_voice_interaction_demo.py
```

**What you'll see:**
```
ğŸ¤ CHIPPY Voice Interaction Demo
âœ… Speech services initialized successfully!
ğŸ§ Listening... (Press Ctrl+C to stop)

ğŸ¤ Recording... Speak now!
ğŸ”Š You said: "What is 5 plus 3?"
ğŸ¤– CHIPPY: "5 plus 3 equals 8. Great question! Addition is when we combine numbers to find their total..."
ğŸµ Playing audio response...
```

### Textbook Processing

Process educational content for CHIPPY's knowledge base:

```bash
python preprocess_textbooks.py
```

This will:
- ğŸ“– Extract text from PDF textbooks
- ğŸ—ï¸ Structure content by grade level
- ğŸ’¾ Generate JSON knowledge files
- ğŸ“Š Create searchable content database

### Testing Individual Components

```bash
# Test speech recognition only
cd azure-speech-to-text/tests
python test_speech_client.py

# Test privacy management
python test_privacy_manager.py
```

---

## ğŸ—ï¸ Architecture

### Project Structure
```
Ai-Agent/
â”œâ”€â”€ ğŸ¤ azure-speech-to-text/          # Core voice interaction system
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ—£ï¸ speech_client.py       # Speech recognition
â”‚   â”‚   â”œâ”€â”€ ğŸ”Š tts_client.py          # Text-to-speech
â”‚   â”‚   â”œâ”€â”€ ğŸŒ rest_speech_client.py  # REST API client
â”‚   â”‚   â”œâ”€â”€ ğŸ›¡ï¸ privacy_manager.py     # Data anonymization
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ config.py              # Configuration management
â”‚   â”‚   â”œâ”€â”€ ğŸ® copy_voice_interaction_demo.py  # Main demo
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ ğŸµ audio_helper.py    # Audio utilities
â”‚   â”‚       â””â”€â”€ ğŸ”„ audio_converter.py # Format conversion
â”‚   â””â”€â”€ tests/                        # Unit tests
â”œâ”€â”€ ğŸ“š textbooks/                     # Source educational materials
â”œâ”€â”€ ğŸ“– processed_textbooks/           # Extracted text content
â”œâ”€â”€ ğŸ“Š processed_json_textbooks/      # Structured knowledge base
â”œâ”€â”€ âš™ï¸ preprocess_textbooks.py        # Content processing
â””â”€â”€ ğŸ“‹ requirements.txt               # Dependencies
```

### Core Components

#### ğŸ¤ Speech Recognition (`speech_client.py`)
- Real-time audio capture
- Azure Speech-to-Text integration
- Noise filtering and audio optimization

#### ğŸ”Š Text-to-Speech (`tts_client.py`)
- Natural voice synthesis
- Multiple voice options
- Audio format optimization

#### ğŸ›¡ï¸ Privacy Manager (`privacy_manager.py`)
- PII detection and anonymization
- Session-based data protection
- Secure data handling

#### ğŸ§  AI Flow Integration
- Intelligent response generation
- Context-aware conversations
- Personalized tutoring strategies

---

## ğŸ¯ Features

### ğŸ¤ Voice Interaction
- **Real-time Speech Recognition**: Converts student speech to text instantly
- **Natural Voice Responses**: High-quality text-to-speech with human-like intonation
- **Multi-language Support**: Configurable for different languages and accents

### ğŸ§  Intelligent Tutoring
- **Adaptive Learning**: Adjusts difficulty based on student responses
- **Curriculum Alignment**: Follows K-8 math standards
- **Contextual Understanding**: Maintains conversation context across interactions

### ğŸ”’ Privacy & Security
- **Data Anonymization**: Removes personally identifiable information
- **Session Management**: Secure session handling
- **Local Processing**: Minimizes cloud data transmission

### ğŸ“š Content Management
- **Curriculum Processing**: Extracts and structures educational content
- **Grade-Level Organization**: Content organized by grade levels (K-8)
- **Searchable Knowledge Base**: Quick access to relevant educational material

---

## ğŸ”§ Configuration

### Audio Settings
```python
# In config.py
AUDIO_CONFIG = {
    'sample_rate': 16000,
    'channels': 1,
    'chunk_size': 1024,
    'format': 'wav'
}
```

### Speech Recognition
```python
SPEECH_CONFIG = {
    'language': 'en-US',
    'profanity_filter': True,
    'enable_dictation': True
}
```

### Privacy Settings
```python
PRIVACY_CONFIG = {
    'anonymize_names': True,
    'hash_identifiers': True,
    'session_timeout': 3600  # 1 hour
}
```

---

## ğŸ§ª Testing

Run the test suite:
```bash
cd azure-speech-to-text
python -m pytest tests/ -v
```

Individual test categories:
```bash
# Test speech recognition
python -m pytest tests/test_speech_client.py -v

# Test privacy features
python -m pytest tests/test_privacy_manager.py -v

# Test audio processing
python -m pytest tests/test_audio_helper.py -v
```

---

## ğŸ¤ Contributing

We welcome contributions!

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch (`git checkout -b feature/amazing-feature`)
3. ğŸ’¾ Commit your changes (`git commit -m 'Add amazing feature'`)
4. ğŸ“¤ Push to the branch (`git push origin feature/amazing-feature`)
5. ğŸ”„ Open a Pull Request

---

## ğŸ†˜ Troubleshooting


**ğŸ”‘ Authentication errors**
- Verify your Azure credentials in `.env`
- Check that your Azure subscription is active
- Ensure the Speech service is available in your region

**ğŸ”Š Audio playback issues**
- Check system volume and audio output device
- Verify audio format compatibility
- Test with different TTS voice options

---

## ğŸ“ Support

- ğŸ’¬ Discord: You know where to find us
- ğŸ› Issues: [GitHub Issues](https://github.com/apex-tutoring-robot/Ai-Agent/issues)

---

<div align="center">

**ğŸŒŸ Star us on GitHub if CHIPPY helps with your educational technology projects! ğŸŒŸ**

Made with â¤ï¸ by the CHIPPY Team

</div>
```
